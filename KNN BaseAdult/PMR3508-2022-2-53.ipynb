{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train_data.csv')\n",
    "df_test = pd.read_csv('test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16280</td>\n",
       "      <td>34</td>\n",
       "      <td>Private</td>\n",
       "      <td>204991</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16281</td>\n",
       "      <td>58</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>310085</td>\n",
       "      <td>10th</td>\n",
       "      <td>6</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Transport-moving</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16282</td>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>146117</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16283</td>\n",
       "      <td>24</td>\n",
       "      <td>Private</td>\n",
       "      <td>138938</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16284</td>\n",
       "      <td>57</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>258883</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Transport-moving</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>5178</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>Hungary</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id  age     workclass  fnlwgt     education  education.num  \\\n",
       "0  16280   34       Private  204991  Some-college             10   \n",
       "1  16281   58     Local-gov  310085          10th              6   \n",
       "2  16282   25       Private  146117  Some-college             10   \n",
       "3  16283   24       Private  138938  Some-college             10   \n",
       "4  16284   57  Self-emp-inc  258883       HS-grad              9   \n",
       "\n",
       "       marital.status         occupation   relationship   race     sex  \\\n",
       "0            Divorced    Exec-managerial      Own-child  White    Male   \n",
       "1  Married-civ-spouse   Transport-moving        Husband  White    Male   \n",
       "2       Never-married  Machine-op-inspct  Not-in-family  White    Male   \n",
       "3            Divorced       Adm-clerical  Not-in-family  White  Female   \n",
       "4  Married-civ-spouse   Transport-moving        Husband  White    Male   \n",
       "\n",
       "   capital.gain  capital.loss  hours.per.week native.country income  \n",
       "0             0             0              44  United-States  <=50K  \n",
       "1             0             0              40  United-States  <=50K  \n",
       "2             0             0              42  United-States  <=50K  \n",
       "3             0             0              40  United-States  <=50K  \n",
       "4          5178             0              60        Hungary   >50K  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective here is to choose four different classifiers and apply to the BaseAdult dataset. I chose the following:\n",
    "- Ranfom Forest\n",
    "- Neural Network (Perceptron)\n",
    "- Logistic Regression\n",
    "- SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To be fair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be a fair comparison, I will pre-process the data exactly like I did with kNN dataset. Hence, these first few cells will be a direct copy and paste from the last assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grouping all the countries that are different from US, Mexico, and '?' in a new category called 'Others'\n",
    "def countries_unite(country):\n",
    "    if country !='United-States' and country != 'Mexico' and country != '?':\n",
    "        country = 'Others'\n",
    "    return country\n",
    "\n",
    "# grouping together some similar values in the marital.status feature\n",
    "def group_marital(status):\n",
    "    if status == 'Married-AF-spouse' or status == 'Married-civ-spouse':\n",
    "        return 'Married'\n",
    "    if status == 'Divorced' or status == 'Separated':\n",
    "        return 'Divorced'\n",
    "    else:\n",
    "        return status\n",
    "\n",
    "def pre_process(df, target=True):\n",
    "    '''\n",
    "    Pre-process our data according to what we did in the last assignment.\n",
    "    '''\n",
    "    #defining X_train and y_train\n",
    "    if target:\n",
    "        X = df[df.columns[:-1]]\n",
    "        y = df[df.columns[-1]]\n",
    "        #encode income\n",
    "        y = y.replace({'<=50K':0, '>50K':1})\n",
    "        #dropping columns that we don't need\n",
    "        X = X.drop(['Id', 'fnlwgt', 'education'], axis=1)\n",
    "\n",
    "        #creating the new variable capital.net\n",
    "        X['capital.net'] = X['capital.gain'] - X['capital.loss']\n",
    "\n",
    "        #dropping 'capital.gain' and 'capital.loss' features\n",
    "        X = X.drop(['capital.gain', 'capital.loss'], axis=1)\n",
    "\n",
    "        #grouping countries\n",
    "        X['native.country'] = X['native.country'].apply(countries_unite)\n",
    "\n",
    "        #grouping marital status\n",
    "        X['marital.status'] = X['marital.status'].apply(group_marital)\n",
    "\n",
    "        #encoding sex feature\n",
    "        X['sex'].replace({'Male':1, 'Female':0}, inplace=True)\n",
    "        \n",
    "        return X, y\n",
    "    else:\n",
    "        X = df\n",
    "        \n",
    "        X = X.drop(['Id', 'fnlwgt', 'education'], axis=1)\n",
    "\n",
    "        #creating the new variable capital.net\n",
    "        X['capital.net'] = X['capital.gain'] - X['capital.loss']\n",
    "\n",
    "        #dropping 'capital.gain' and 'capital.loss' features\n",
    "        X = X.drop(['capital.gain', 'capital.loss'], axis=1)\n",
    "\n",
    "        #grouping countries\n",
    "        X['native.country'] = X['native.country'].apply(countries_unite)\n",
    "\n",
    "        #grouping marital status\n",
    "        X['marital.status'] = X['marital.status'].apply(group_marital)\n",
    "\n",
    "        #encoding sex feature\n",
    "        X['sex'].replace({'Male':1, 'Female':0}, inplace=True)\n",
    "    \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = pre_process(df_train, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding and normalizing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is necessary to encode and normalize our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#defining our categorical features:\n",
    "X_train_cat = [i for i in X_train.columns if X_train.dtypes[i]=='object']\n",
    "\n",
    "#defining our numerical features:\n",
    "X_train_num = [i for i in X_train.columns if X_train.dtypes[i]=='int64' or X_train.dtypes[i]=='float64']\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "#looping in our categorical columns, we encode them:\n",
    "for i in X_train_cat:\n",
    "    X_train[i] = label_encoder.fit_transform(X_train[i].astype(str))\n",
    "\n",
    "#now we normalize our data\n",
    "scaler = StandardScaler()\n",
    "X_train[X_train_cat] = scaler.fit_transform(X_train[X_train_cat]) \n",
    "X_train[X_train_num] = scaler.fit_transform(X_train[X_train_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "      <th>capital.net</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.335886</td>\n",
       "      <td>0.090121</td>\n",
       "      <td>-0.031325</td>\n",
       "      <td>-1.338107</td>\n",
       "      <td>-0.608434</td>\n",
       "      <td>0.966924</td>\n",
       "      <td>0.393675</td>\n",
       "      <td>0.703087</td>\n",
       "      <td>0.288524</td>\n",
       "      <td>0.301208</td>\n",
       "      <td>-0.133663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.423589</td>\n",
       "      <td>-1.283640</td>\n",
       "      <td>-1.586131</td>\n",
       "      <td>-0.497871</td>\n",
       "      <td>1.756334</td>\n",
       "      <td>-0.900177</td>\n",
       "      <td>0.393675</td>\n",
       "      <td>0.703087</td>\n",
       "      <td>-0.035430</td>\n",
       "      <td>0.301208</td>\n",
       "      <td>-0.133663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.995689</td>\n",
       "      <td>0.090121</td>\n",
       "      <td>-0.031325</td>\n",
       "      <td>1.182601</td>\n",
       "      <td>0.100997</td>\n",
       "      <td>-0.277810</td>\n",
       "      <td>0.393675</td>\n",
       "      <td>0.703087</td>\n",
       "      <td>0.126547</td>\n",
       "      <td>0.301208</td>\n",
       "      <td>-0.133663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.069001</td>\n",
       "      <td>0.090121</td>\n",
       "      <td>-0.031325</td>\n",
       "      <td>-1.338107</td>\n",
       "      <td>-1.317864</td>\n",
       "      <td>-0.277810</td>\n",
       "      <td>0.393675</td>\n",
       "      <td>-1.422298</td>\n",
       "      <td>-0.035430</td>\n",
       "      <td>0.301208</td>\n",
       "      <td>-0.133663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.350277</td>\n",
       "      <td>0.777002</td>\n",
       "      <td>-0.420027</td>\n",
       "      <td>-0.497871</td>\n",
       "      <td>1.756334</td>\n",
       "      <td>-0.900177</td>\n",
       "      <td>0.393675</td>\n",
       "      <td>0.703087</td>\n",
       "      <td>1.584340</td>\n",
       "      <td>-1.584818</td>\n",
       "      <td>0.565218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  workclass  education.num  marital.status  occupation  \\\n",
       "0 -0.335886   0.090121      -0.031325       -1.338107   -0.608434   \n",
       "1  1.423589  -1.283640      -1.586131       -0.497871    1.756334   \n",
       "2 -0.995689   0.090121      -0.031325        1.182601    0.100997   \n",
       "3 -1.069001   0.090121      -0.031325       -1.338107   -1.317864   \n",
       "4  1.350277   0.777002      -0.420027       -0.497871    1.756334   \n",
       "\n",
       "   relationship      race       sex  hours.per.week  native.country  \\\n",
       "0      0.966924  0.393675  0.703087        0.288524        0.301208   \n",
       "1     -0.900177  0.393675  0.703087       -0.035430        0.301208   \n",
       "2     -0.277810  0.393675  0.703087        0.126547        0.301208   \n",
       "3     -0.277810  0.393675 -1.422298       -0.035430        0.301208   \n",
       "4     -0.900177  0.393675  0.703087        1.584340       -1.584818   \n",
       "\n",
       "   capital.net  \n",
       "0    -0.133663  \n",
       "1    -0.133663  \n",
       "2    -0.133663  \n",
       "3    -0.133663  \n",
       "4     0.565218  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN (Revisited)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For starters (and for the sake of comparison), we shall tune a kNN classifier again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GridSearchCV function uses a dictionary of parameters and trains the dataset using these parameters. Then, the best set of parameters (in the case of kNN there is only one) can be chosen. The \"best\" set is chosen based on the accuracy of the model, measured through a K-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=KNeighborsClassifier(), n_jobs=-1,\n",
       "             param_grid={'n_neighbors': array([15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31,\n",
       "       32, 33, 34])})"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search = dict(n_neighbors = np.arange(15, 35,1, dtype=int))\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn_grid = GridSearchCV(knn,\n",
    "                       grid_search,\n",
    "                       cv=5,\n",
    "                       n_jobs=-1)\n",
    "knn_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best choice of parameters was: {'n_neighbors': 26}\n"
     ]
    }
   ],
   "source": [
    "print('The best choice of parameters was:',knn_grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this good estimation to train our model and estimate its statistics (accuracy, precision, recall, and f1-score) using cross validation again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The scores of the kNN Classifier were:\n",
      "\n",
      "Average accuracy in cv=10: 0.84 \n",
      "\n",
      "Average precision in cv=10: 0.80 \n",
      "\n",
      "Average recall in cv=10: 0.74 \n",
      "\n",
      "Average F1 in cv=10: 0.76 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "scoring = {'acc': 'accuracy',\n",
    "           'prec_macro': 'precision_macro',\n",
    "           'rec_macro': 'recall_macro',\n",
    "          'f1' : 'f1_macro'}\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=26)\n",
    "\n",
    "knn_scores = cross_validate(knn, X_train, y_train, scoring=scoring, cv=10, n_jobs=-1)\n",
    "\n",
    "print('The scores of the kNN Classifier were:')\n",
    "print()\n",
    "print('Average accuracy in cv=10: {:.2f} \\n' .format(knn_scores['test_acc'].mean()))\n",
    "print('Average precision in cv=10: {:.2f} \\n' .format(knn_scores['test_prec_macro'].mean()))\n",
    "print('Average recall in cv=10: {:.2f} \\n' .format(knn_scores['test_rec_macro'].mean()))\n",
    "print('Average F1 in cv=10: {:.2f} \\n' .format(knn_scores['test_f1'].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use a randomized search for the best hyperparameters of our trees (in fact, this technique will be used for all the subsequent classifiers). RandomizedSearchCV chooses a random set of parameters from a dictionary that we create and use these parameters to train and test (using cross-validation) the model and look for the best set of parameters. In this case, \"best\" is the one that results in CV biggest accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "/opt/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:688: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed: 12.6min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed: 17.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(), n_iter=40,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'criterion': ['gini', 'entropy'],\n",
       "                                        'max_depth': [5, 10, 20, 50, 75, 100,\n",
       "                                                      150, 200],\n",
       "                                        'min_samples_split': [2, 3, 4, 5, 6, 7,\n",
       "                                                              8, 9, 10],\n",
       "                                        'n_estimators': array([ 100,  150,  200,  250,  300,  350,  400,  450,  500,  550,  600,\n",
       "        650,  700,  750,  800,  850,  900,  950, 1000, 1050, 1100, 1150,\n",
       "       1200, 1250, 1300, 1350, 1400, 1450, 1500, 1550, 1600, 1650, 1700,\n",
       "       1750, 1800, 1850, 1900, 1950, 2000, 2050, 2100, 2150, 2200, 2250,\n",
       "       2300, 2350, 2400, 2450, 2500, 2550, 2600, 2650, 2700, 2750, 2800,\n",
       "       2850, 2900, 2950])},\n",
       "                   random_state=1, verbose=2)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of trees in the forest\n",
    "n_estimators = np.arange(100, 3000, 50, dtype=int)\n",
    "\n",
    "#maximum number of splittings\n",
    "max_depth = [5, 10, 20, 50, 75, 100, 150, 200]\n",
    "\n",
    "#minimum number of samples to split a node\n",
    "min_samples_split = [int(x) for x in np.linspace(start=2, stop=10, num=9)]\n",
    "\n",
    "#splitting criterion:\n",
    "criterion = ['gini', 'entropy']\n",
    "\n",
    "#creating the dictionary of parameters that the randomized search will use\n",
    "random_grid = {'n_estimators':n_estimators,\n",
    "              'max_depth':max_depth,\n",
    "              'min_samples_split':min_samples_split,\n",
    "              'criterion':criterion}\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "#now we set our RandomizedSearchCV function, with 40 iterations and 5-fold cv\n",
    "rf_random = RandomizedSearchCV(estimator=rf,\n",
    "                              param_distributions=random_grid,\n",
    "                              n_iter=40,\n",
    "                              cv=5,\n",
    "                              verbose=2,\n",
    "                              random_state=1,\n",
    "                              n_jobs=-1)\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the search, the best parameters and the best score found were:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best set of parameters: {'n_estimators': 1500, 'min_samples_split': 9, 'max_depth': 20, 'criterion': 'gini'}\n"
     ]
    }
   ],
   "source": [
    "print('Best set of parameters:',rf_random.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use these parameters to find the metrics of our classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The scores of the Random Forest Classifier were:\n",
      "\n",
      "Average accuracy in cv=10: 0.87 \n",
      "\n",
      "Average precision in cv=10: 0.83 \n",
      "\n",
      "Average recall in cv=10: 0.79 \n",
      "\n",
      "Average F1 in cv=10: 0.81 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "scoring = {'acc': 'accuracy',\n",
    "           'prec_macro': 'precision_macro',\n",
    "           'rec_macro': 'recall_macro',\n",
    "          'f1' : 'f1_macro'}\n",
    "\n",
    "random_forest = RandomForestClassifier(n_estimators = 1500, \n",
    "                                       min_samples_split=9,\n",
    "                                       max_depth=20,\n",
    "                                       criterion='gini')\n",
    "\n",
    "rf_scores = cross_validate(random_forest, X_train, y_train, scoring=scoring, cv=10, n_jobs=-1)\n",
    "\n",
    "print('The scores of the Random Forest Classifier were:')\n",
    "print()\n",
    "print('Average accuracy in cv=10: {:.2f} \\n' .format(rf_scores['test_acc'].mean()))\n",
    "print('Average precision in cv=10: {:.2f} \\n' .format(rf_scores['test_prec_macro'].mean()))\n",
    "print('Average recall in cv=10: {:.2f} \\n' .format(rf_scores['test_rec_macro'].mean()))\n",
    "print('Average F1 in cv=10: {:.2f} \\n' .format(rf_scores['test_f1'].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP (Neural Network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use the adam method, choosing from a tanh and a ReLU activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:278: UserWarning: The total space of parameters 6 is smaller than n_iter=30. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  1.1min finished\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=MLPClassifier(), n_iter=30, n_jobs=-1,\n",
       "                   param_distributions={'activation': ['tanh', 'relu'],\n",
       "                                        'hidden_layer_sizes': [[25, 25],\n",
       "                                                               [10, 25],\n",
       "                                                               [50]]},\n",
       "                   random_state=1, verbose=2)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_layer_sizes = [[25,25],[10,25],[50,]]\n",
    "\n",
    "activation = ['tanh', 'relu']\n",
    "\n",
    "random_grid = {'hidden_layer_sizes':hidden_layer_sizes,\n",
    "              'activation':activation}\n",
    "\n",
    "MLP = MLPClassifier()\n",
    "\n",
    "MLP_random = RandomizedSearchCV(estimator=MLP,\n",
    "                              param_distributions=random_grid,\n",
    "                              n_iter=30,\n",
    "                              cv=5,\n",
    "                              verbose=2,\n",
    "                              random_state=1,\n",
    "                              n_jobs=-1)\n",
    "MLP_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best set of parameters found was:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best set of MLP parameters: {'hidden_layer_sizes': [50], 'activation': 'tanh'}\n"
     ]
    }
   ],
   "source": [
    "print('Best set of MLP parameters:',MLP_random.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use cross validation to estimate the statistics of our classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The scores of the MLP Classifier were:\n",
      "\n",
      "Average accuracy in cv=10: 0.85 \n",
      "\n",
      "Average precision in cv=10: 0.81 \n",
      "\n",
      "Average recall in cv=10: 0.77 \n",
      "\n",
      "Average F1 in cv=10: 0.78 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "MLP = MLPClassifier(hidden_layer_sizes=(50,), activation='tanh')\n",
    "\n",
    "MLP_scores = cross_validate(MLP, X_train, y_train, scoring=scoring, cv=10, n_jobs=-1)\n",
    "\n",
    "print('The scores of the MLP Classifier were:')\n",
    "print()\n",
    "print('Average accuracy in cv=10: {:.2f} \\n' .format(MLP_scores['test_acc'].mean()))\n",
    "print('Average precision in cv=10: {:.2f} \\n' .format(MLP_scores['test_prec_macro'].mean()))\n",
    "print('Average recall in cv=10: {:.2f} \\n' .format(MLP_scores['test_rec_macro'].mean()))\n",
    "print('Average F1 in cv=10: {:.2f} \\n' .format(MLP_scores['test_f1'].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid={'C': array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. , 1.1, 1.2, 1.3,\n",
       "       1.4])})"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = dict(C=np.arange(0.1, 1.5, 0.1))\n",
    "log_reg = LogisticRegression()\n",
    "log_reg_grid = GridSearchCV(log_reg,\n",
    "                           grid,\n",
    "                           cv=5,\n",
    "                           n_jobs=-1)\n",
    "log_reg_grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search best parameters was: {'C': 0.4}\n"
     ]
    }
   ],
   "source": [
    "print('Grid search best parameters was:', log_reg_grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing the logistic regression with this choice of parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The scores of the LogisticRegression Classifier were:\n",
      "\n",
      "Average accuracy in cv=10: 0.82 \n",
      "\n",
      "Average precision in cv=10: 0.77 \n",
      "\n",
      "Average recall in cv=10: 0.69 \n",
      "\n",
      "Average F1 in cv=10: 0.72 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "LogReg = LogisticRegression(C=0.4)\n",
    "\n",
    "log_scores = cross_validate(LogReg, X_train, y_train, scoring=scoring, cv=10, n_jobs=-1)\n",
    "\n",
    "print('The scores of the LogisticRegression Classifier were:')\n",
    "print()\n",
    "print('Average accuracy in cv=10: {:.2f} \\n' .format(log_scores['test_acc'].mean()))\n",
    "print('Average precision in cv=10: {:.2f} \\n' .format(log_scores['test_prec_macro'].mean()))\n",
    "print('Average recall in cv=10: {:.2f} \\n' .format(log_scores['test_rec_macro'].mean()))\n",
    "print('Average F1 in cv=10: {:.2f} \\n' .format(log_scores['test_f1'].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 125 out of 125 | elapsed:  5.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=SVC(), n_iter=25, n_jobs=-1,\n",
       "                   param_distributions={'C': array([0.5, 0.8, 1.1, 1.4, 1.7]),\n",
       "                                        'break_ties': [True, False],\n",
       "                                        'degree': [1, 2, 3],\n",
       "                                        'kernel': ['linear', 'poly', 'rbf',\n",
       "                                                   'sigmoid']},\n",
       "                   random_state=1, verbose=2)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = np.arange(0.5, 2, 0.3)\n",
    "kernel = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "break_ties = [True, False]\n",
    "degree = [int(i) for i in range(1,4)]\n",
    "\n",
    "random_grid = {'C': C,\n",
    "              'kernel': kernel,\n",
    "              'break_ties': break_ties,\n",
    "              'degree': degree}\n",
    "\n",
    "SVMClassifier = SVC()\n",
    "\n",
    "SVM_random = RandomizedSearchCV(estimator=SVMClassifier,\n",
    "                              param_distributions=random_grid,\n",
    "                              n_iter=25,\n",
    "                              cv=5,\n",
    "                              verbose=2,\n",
    "                              random_state=1,\n",
    "                              n_jobs=-1)\n",
    "SVM_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best set of parameters is: {'kernel': 'rbf', 'degree': 1, 'break_ties': True, 'C': 1.7000000000000002}\n"
     ]
    }
   ],
   "source": [
    "print('Best set of parameters is:',SVM_random.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The scores of the SVM Classifier were:\n",
      "\n",
      "Average accuracy in cv=10: 0.85 \n",
      "\n",
      "Average precision in cv=10: 0.82 \n",
      "\n",
      "Average recall in cv=10: 0.74 \n",
      "\n",
      "Average F1 in cv=10: 0.76 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "SVMClassifier = SVC(C=1.7, kernel='rbf', break_ties=True, degree=1)\n",
    "SVM_scores = cross_validate(SVMClassifier, X_train, y_train, cv=10, scoring = scoring, n_jobs=-1)\n",
    "\n",
    "print('The scores of the SVM Classifier were:')\n",
    "print()\n",
    "print('Average accuracy in cv=10: {:.2f} \\n' .format(SVM_scores['test_acc'].mean()))\n",
    "print('Average precision in cv=10: {:.2f} \\n' .format(SVM_scores['test_prec_macro'].mean()))\n",
    "print('Average recall in cv=10: {:.2f} \\n' .format(SVM_scores['test_rec_macro'].mean()))\n",
    "print('Average F1 in cv=10: {:.2f} \\n' .format(SVM_scores['test_f1'].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bellow I gathered all the statistics of each model to compare them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>kNN</th>\n",
       "      <td>0.840848</td>\n",
       "      <td>0.796086</td>\n",
       "      <td>0.739874</td>\n",
       "      <td>0.760798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.866892</td>\n",
       "      <td>0.831383</td>\n",
       "      <td>0.787549</td>\n",
       "      <td>0.805623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>0.852948</td>\n",
       "      <td>0.810314</td>\n",
       "      <td>0.767219</td>\n",
       "      <td>0.784503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.821069</td>\n",
       "      <td>0.771576</td>\n",
       "      <td>0.694628</td>\n",
       "      <td>0.718216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.846959</td>\n",
       "      <td>0.815951</td>\n",
       "      <td>0.735410</td>\n",
       "      <td>0.762372</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Accuracy  Precision    Recall  F1-Score\n",
       "kNN                  0.840848   0.796086  0.739874  0.760798\n",
       "Random Forest        0.866892   0.831383  0.787549  0.805623\n",
       "MLP                  0.852948   0.810314  0.767219  0.784503\n",
       "Logistic Regression  0.821069   0.771576  0.694628  0.718216\n",
       "SVM                  0.846959   0.815951  0.735410  0.762372"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifiers = ['kNN', 'Random Forest', 'MLP', 'Logistic Regression', 'SVM']\n",
    "accuracies = [knn_scores['test_acc'].mean(), \n",
    "             rf_scores['test_acc'].mean(),\n",
    "             MLP_scores['test_acc'].mean(),\n",
    "             log_scores['test_acc'].mean(),\n",
    "             SVM_scores['test_acc'].mean()]\n",
    "\n",
    "precisions = [knn_scores['test_prec_macro'].mean(), \n",
    "             rf_scores['test_prec_macro'].mean(),\n",
    "             MLP_scores['test_prec_macro'].mean(),\n",
    "             log_scores['test_prec_macro'].mean(),\n",
    "             SVM_scores['test_prec_macro'].mean()]\n",
    "\n",
    "recalls = [knn_scores['test_rec_macro'].mean(), \n",
    "             rf_scores['test_rec_macro'].mean(),\n",
    "             MLP_scores['test_rec_macro'].mean(),\n",
    "             log_scores['test_rec_macro'].mean(),\n",
    "             SVM_scores['test_rec_macro'].mean()]\n",
    "\n",
    "f1s = [knn_scores['test_f1'].mean(), \n",
    "             rf_scores['test_f1'].mean(),\n",
    "             MLP_scores['test_f1'].mean(),\n",
    "             log_scores['test_f1'].mean(),\n",
    "             SVM_scores['test_f1'].mean()]\n",
    "\n",
    "df_models = pd.DataFrame({'Accuracy':accuracies, \n",
    "              'Precision':precisions,\n",
    "             'Recall':recalls,\n",
    "             'F1-Score':f1s},\n",
    "            index=classifiers)\n",
    "\n",
    "df_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By accuracy performance, the selected model will be the Random Forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction of the test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, with our best performance model chosen, we can fit it with our train set, and use it to predict the target labels of our test dataset.\n",
    "\n",
    "First, we pre-process and normalize the data in the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pre_process(df_test, target=False)\n",
    "\n",
    "#defining our categorical features:\n",
    "X_test_cat = [i for i in X_test.columns if X_test.dtypes[i]=='object']\n",
    "\n",
    "#defining our numerical features:\n",
    "X_test_num = [i for i in X_test.columns if X_test.dtypes[i]=='int64' or X_test.dtypes[i]=='float64']\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "#looping in our categorical columns, we encode them:\n",
    "for i in X_test_cat:\n",
    "    X_test[i] = label_encoder.fit_transform(X_test[i].astype(str))\n",
    "\n",
    "#now we normalize our data\n",
    "scaler = StandardScaler()\n",
    "X_test[X_test_cat] = scaler.fit_transform(X_test[X_test_cat]) \n",
    "X_test[X_test_num] = scaler.fit_transform(X_test[X_test_num])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we fit and predict the target labels, creating a dataframe containing the final results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16275</th>\n",
       "      <td>16275</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16276</th>\n",
       "      <td>16276</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16277</th>\n",
       "      <td>16277</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16278</th>\n",
       "      <td>16278</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16279</th>\n",
       "      <td>16279</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16280 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Id income\n",
       "0          0  <=50K\n",
       "1          1   >50K\n",
       "2          2  <=50K\n",
       "3          3  <=50K\n",
       "4          4   >50K\n",
       "...      ...    ...\n",
       "16275  16275  <=50K\n",
       "16276  16276  <=50K\n",
       "16277  16277  <=50K\n",
       "16278  16278  <=50K\n",
       "16279  16279   >50K\n",
       "\n",
       "[16280 rows x 2 columns]"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result = pd.DataFrame(columns=['Id', 'income'])\n",
    "\n",
    "final_result['Id'] = df_test['Id']\n",
    "final_result['income'] = random_forest.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "final_result['income'].replace({0: '<=50K', 1:'>50K'}, inplace=True)\n",
    "\n",
    "final_result\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result.to_csv('predictions.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
